{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 0.3+ 相似度搜尋方法比較\n",
    "比較不同相似度搜尋方法的性能與特性\n",
    "\n",
    "需求套件:\n",
    "- langchain>=0.3.0\n",
    "- langchain-community>=0.0.1\n",
    "- rank_bm25>=0.2.2\n",
    "- scikit-learn>=1.3.0\n",
    "- pandas>=2.0.0\n",
    "- numpy>=1.24.0\n",
    "- python-dotenv>=0.19.0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search 檢索技術分析 (基於固定 Embedding Model 與 FAISS 向量資料庫)\n",
    "\n",
    "---\n",
    "\n",
    "## 方法特性分析表\n",
    "\n",
    "| **特性**         | FAISS | Annoy | ScaNN | HNSW | DPR (Dense Retriever) | ColBERT | Contriever | Hybrid Search (BM25+Vectors) |\n",
    "|-----------------|:-----:|:-----:|:-----:|:-----:|:---------------------:|:-------:|:---------:|:--------------------------:|\n",
    "| **檢索準確性**   |   △   |   △   |   ○   |   ○   |           ○           |    ○    |     ○     |             ○              |\n",
    "| **檢索延遲**     |   ○   |   ○   |   ○   |   △   |           △           |    △    |     △     |             △              |\n",
    "| **擴展性**       |   ○   |   ○   |   ○   |   ○   |           △           |    △    |     △     |             △              |\n",
    "| **計算成本**     |   ○   |   ○   |   ○   |   △   |           △           |    △    |     △     |             △              |\n",
    "| **索引更新效率** |   △   |   △   |   ○   |   ○   |           ×           |    ×    |     ×     |             △              |\n",
    "| **查詢效率**     |   ○   |   ○   |   ○   |   △   |           △           |    △    |     △     |             △              |\n",
    "\n",
    "---\n",
    "\n",
    "## 問題特性分析表\n",
    "\n",
    "| **應用領域**        | FAISS | Annoy | ScaNN | HNSW | DPR (Dense Retriever) | ColBERT | Contriever | Hybrid Search (BM25+Vectors) |\n",
    "|-----------------|:-----:|:-----:|:-----:|:-----:|:---------------------:|:-------:|:---------:|:--------------------------:|\n",
    "| **近似最近鄰檢索（ANN）**  |   ○   |   ○   |   ○   |   ○   |           △           |    △    |     △     |             △              |\n",
    "| **大規模數據檢索**   |   ○   |   △   |   ○   |   ○   |           △           |    △    |     △     |             △              |\n",
    "| **低延遲檢索**     |   ○   |   ○   |   ○   |   △   |           △           |    △    |     △     |             △              |\n",
    "| **文本相似性檢索**   |   △   |   △   |   ○   |   ○   |           ○           |    ○    |     ○     |             ○              |\n",
    "| **知識檢索（Knowledge Retrieval）** |   △   |   △   |   ○   |   ○   |           ○           |    ○    |     ○     |             ○              |\n",
    "\n",
    "---\n",
    "\n",
    "## 方法特性 vs. 問題特性 矩陣比較表\n",
    "\n",
    "| **方法特性 / 應用領域** | **ANN（近似最近鄰）** | **大規模數據檢索** | **低延遲檢索** | **文本相似性檢索** | **知識檢索** |\n",
    "|----------------------|:----------------:|:----------------:|:--------------:|:----------------:|:--------------:|\n",
    "| **檢索準確性**       |        △        |        ○        |        △        |        ○        |        ○        |\n",
    "| **檢索延遲**         |        ○        |        △        |        ○        |        △        |        △        |\n",
    "| **擴展性**           |        ○        |        ○        |        △        |        △        |        △        |\n",
    "| **計算成本**         |        ○        |        ○        |        △        |        △        |        △        |\n",
    "| **索引更新效率**     |        △        |        △        |        △        |        ×        |        ×        |\n",
    "| **查詢效率**         |        ○        |        ○        |        ○        |        △        |        △        |\n",
    "\n",
    "---\n",
    "\n",
    "## LLM RAG 內部檢索技術影響分析\n",
    "\n",
    "LLM RAG 本質上依賴向量檢索技術來進行檢索擴充，以下是不同檢索技術在 LLM RAG 內的影響：\n",
    "\n",
    "| **檢索技術** | **影響點** |\n",
    "|-------------|-----------|\n",
    "| **FAISS** | 高效檢索速度，適合大規模知識檢索，但無法進行語義推理 |\n",
    "| **ScaNN** | 速度優於 FAISS，適合低延遲檢索應用 |\n",
    "| **DPR (Dense Retriever)** | 語義檢索準確度高，但擴展性受限，對大規模數據檢索成本較高 |\n",
    "| **ColBERT** | 高語義檢索能力，適合精準知識檢索，但查詢延遲較高 |\n",
    "| **Hybrid Search (BM25+Vectors)** | 提供關鍵字檢索+語義檢索混合方案，適合通用應用 |\n",
    "  \n",
    "---\n",
    "\n",
    "## 符號意義\n",
    "- **○**：表現優異或高度相關  \n",
    "- **△**：表現一般或部分適用  \n",
    "- **×**：表現較差或不適用  \n",
    "\n",
    "---\n",
    "\n",
    "## 指標量化\n",
    "\n",
    "| **指標名稱**    | **量化評測方式**                      | **可參考基準**          |\n",
    "|----------------|--------------------------------|------------------|\n",
    "| **檢索準確性**  | Recall@K / Precision@K / MRR | BEIR、MTEB       |\n",
    "| **檢索延遲**    | 查詢平均延遲（毫秒）         | BEIR、MTEB       |\n",
    "| **擴展性**      | 檢索時間 vs. 數據規模（log-scale） | FAISS Benchmark  |\n",
    "| **計算成本**    | FLOPs（浮點運算量）/ 記憶體使用率 | Papers With Code |\n",
    "| **索引更新效率** | 新數據插入對查詢效率的影響 | FAISS Benchmark  |\n",
    "| **查詢效率**    | 每秒查詢數（QPS）             | BEIR、MTEB       |\n",
    "\n",
    "---\n",
    "\n",
    "## 適用場景推薦\n",
    "\n",
    "| **應用場景** | **推薦技術** |\n",
    "|-------------|-------------|\n",
    "| **近似最近鄰檢索（ANN）** | FAISS, ScaNN, HNSW |\n",
    "| **大規模數據檢索** | FAISS, ScaNN, HNSW |\n",
    "| **低延遲檢索** | FAISS, Annoy, ScaNN |\n",
    "| **文本相似性檢索** | DPR, ColBERT, Contriever, Hybrid Search |\n",
    "| **知識檢索** | DPR, ColBERT, Contriever, Hybrid Search |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import (\n",
    "    cosine_similarity,\n",
    "    euclidean_distances\n",
    ")\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import (\n",
    "    BM25Retriever,\n",
    "    EnsembleRetriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 設定日誌\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 載入環境變數\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "jina_api_key = os.getenv(\"JINA_API_KEY\")\n",
    "bge_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SearchMetrics:\n",
    "    \"\"\"搜尋方法評估指標\"\"\"\n",
    "    name: str\n",
    "    search_time: float\n",
    "    precision_at_k: float\n",
    "    recall_at_k: float\n",
    "    mrr: float\n",
    "    ndcg: float\n",
    "    diversity: float\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SearchMethodEvaluator:\n",
    "    \"\"\"相似度搜尋方法評估器\"\"\"\n",
    "    def __init__(self):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.metrics: List[SearchMetrics] = []\n",
    "        \n",
    "    def prepare_test_data(self) -> Tuple[List[str], List[str], List[List[int]]]:\n",
    "        \"\"\"準備測試數據\"\"\"\n",
    "        # 準備文檔集合\n",
    "        documents = [\n",
    "            \"Machine learning is a subset of artificial intelligence.\",\n",
    "            \"Deep learning uses neural networks with multiple layers.\",\n",
    "            \"Natural language processing helps computers understand human language.\",\n",
    "            \"Computer vision focuses on helping machines interpret visual information.\",\n",
    "            \"Reinforcement learning is learning through interaction with an environment.\",\n",
    "            \"Supervised learning uses labeled training data.\",\n",
    "            \"Unsupervised learning finds patterns in unlabeled data.\",\n",
    "            \"Neural networks are inspired by biological brain structures.\",\n",
    "            \"Convolutional neural networks are commonly used in image processing.\",\n",
    "            \"Recurrent neural networks are good at processing sequential data.\"\n",
    "        ]\n",
    "        \n",
    "        # 準備查詢\n",
    "        queries = [\n",
    "            \"What is machine learning?\",\n",
    "            \"How do neural networks work?\",\n",
    "            \"Explain deep learning concepts\",\n",
    "            \"Tell me about computer vision\",\n",
    "            \"What is natural language processing?\"\n",
    "        ]\n",
    "        \n",
    "        # 準備相關性標記（1表示相關，0表示不相關）\n",
    "        relevance = [\n",
    "            [1, 0, 0, 0, 0, 1, 1, 0, 0, 0],  # 對於查詢1\n",
    "            [0, 1, 0, 0, 0, 0, 0, 1, 1, 1],  # 對於查詢2\n",
    "            [0, 1, 0, 0, 0, 0, 0, 1, 1, 0],  # 對於查詢3\n",
    "            [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],  # 對於查詢4\n",
    "            [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]   # 對於查詢5\n",
    "        ]\n",
    "        \n",
    "        return documents, queries, relevance\n",
    "\n",
    "    def calculate_metrics(\n",
    "        self,\n",
    "        results: List[int],\n",
    "        relevance: List[int],\n",
    "        k: int = 5\n",
    "    ) -> Tuple[float, float, float, float]:\n",
    "        \"\"\"計算評估指標\"\"\"\n",
    "        # Precision@K\n",
    "        precision = sum(relevance[i] for i in results[:k]) / k\n",
    "        \n",
    "        # Recall@K\n",
    "        total_relevant = sum(relevance)\n",
    "        recall = sum(relevance[i] for i in results[:k]) / total_relevant if total_relevant > 0 else 0\n",
    "        \n",
    "        # MRR (Mean Reciprocal Rank)\n",
    "        for i, doc_id in enumerate(results, 1):\n",
    "            if relevance[doc_id] == 1:\n",
    "                mrr = 1.0 / i\n",
    "                break\n",
    "        else:\n",
    "            mrr = 0\n",
    "        \n",
    "        # NDCG@K\n",
    "        dcg = sum(relevance[i] / np.log2(rank + 2) for rank, i in enumerate(results[:k]))\n",
    "        ideal_results = sorted(range(len(relevance)), key=lambda i: relevance[i], reverse=True)\n",
    "        idcg = sum(relevance[i] / np.log2(rank + 2) for rank, i in enumerate(ideal_results[:k]))\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "        \n",
    "        return precision, recall, mrr, ndcg\n",
    "\n",
    "    def calculate_diversity(self, results: List[int], embeddings: List[np.ndarray]) -> float:\n",
    "        \"\"\"計算結果多樣性\"\"\"\n",
    "        if len(results) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        # 獲取結果文檔的嵌入向量\n",
    "        result_embeddings = [embeddings[i] for i in results]\n",
    "        \n",
    "        # 計算結果之間的平均餘弦相似度\n",
    "        similarities = cosine_similarity(result_embeddings)\n",
    "        \n",
    "        # 計算多樣性分數 (1 - 平均相似度)\n",
    "        n = len(results)\n",
    "        diversity = 1.0 - (np.sum(similarities) - n) / (n * (n - 1))\n",
    "        \n",
    "        return diversity\n",
    "\n",
    "    def evaluate_cosine(\n",
    "        self,\n",
    "        documents: List[str],\n",
    "        queries: List[str],\n",
    "        relevance: List[List[int]]\n",
    "    ) -> SearchMetrics:\n",
    "        \"\"\"評估餘弦相似度搜尋\"\"\"\n",
    "        try:\n",
    "            # 獲取嵌入向量\n",
    "            doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "            doc_embeddings = np.array(doc_embeddings)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            metrics_list = []\n",
    "            \n",
    "            for query, rel in zip(queries, relevance):\n",
    "                # 獲取查詢嵌入\n",
    "                query_embedding = self.embeddings.embed_query(query)\n",
    "                query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "                \n",
    "                # 計算相似度\n",
    "                similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "                results = np.argsort(-similarities)[:5].tolist()\n",
    "                \n",
    "                # 計算評估指標\n",
    "                precision, recall, mrr, ndcg = self.calculate_metrics(results, rel)\n",
    "                metrics_list.append((precision, recall, mrr, ndcg))\n",
    "            \n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            # 計算平均指標\n",
    "            avg_metrics = np.mean(metrics_list, axis=0)\n",
    "            diversity = self.calculate_diversity(results, doc_embeddings)\n",
    "            \n",
    "            return SearchMetrics(\n",
    "                name=\"Cosine Similarity\",\n",
    "                search_time=search_time,\n",
    "                precision_at_k=avg_metrics[0],\n",
    "                recall_at_k=avg_metrics[1],\n",
    "                mrr=avg_metrics[2],\n",
    "                ndcg=avg_metrics[3],\n",
    "                diversity=diversity,\n",
    "                explanation=\"基於向量空間中的夾角計算相似度\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"餘弦相似度評估失敗: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def evaluate_mmr(\n",
    "        self,\n",
    "        documents: List[str],\n",
    "        queries: List[str],\n",
    "        relevance: List[List[int]],\n",
    "        lambda_param: float = 0.5\n",
    "    ) -> SearchMetrics:\n",
    "        \"\"\"評估 MMR (Maximal Marginal Relevance) 搜尋\"\"\"\n",
    "        try:\n",
    "            # 獲取嵌入向量\n",
    "            doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "            doc_embeddings = np.array(doc_embeddings)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            metrics_list = []\n",
    "            \n",
    "            for query, rel in zip(queries, relevance):\n",
    "                query_embedding = self.embeddings.embed_query(query)\n",
    "                query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "                \n",
    "                # MMR 實現\n",
    "                remaining_docs = list(range(len(documents)))\n",
    "                selected = []\n",
    "                \n",
    "                while len(selected) < 5 and remaining_docs:\n",
    "                    # 計算相關性分數\n",
    "                    relevance_scores = cosine_similarity(\n",
    "                        query_embedding,\n",
    "                        doc_embeddings[remaining_docs]\n",
    "                    )[0]\n",
    "                    \n",
    "                    if not selected:\n",
    "                        # 第一個文檔：選擇最相關的\n",
    "                        idx = np.argmax(relevance_scores)\n",
    "                        selected.append(remaining_docs[idx])\n",
    "                        del remaining_docs[idx]\n",
    "                    else:\n",
    "                        # 後續文檔：考慮相關性和多樣性\n",
    "                        diversity_scores = np.max(cosine_similarity(\n",
    "                            doc_embeddings[remaining_docs],\n",
    "                            doc_embeddings[selected]\n",
    "                        ), axis=1)\n",
    "                        \n",
    "                        mmr_scores = lambda_param * relevance_scores - \\\n",
    "                                   (1 - lambda_param) * diversity_scores\n",
    "                        \n",
    "                        idx = np.argmax(mmr_scores)\n",
    "                        selected.append(remaining_docs[idx])\n",
    "                        del remaining_docs[idx]\n",
    "                \n",
    "                # 計算評估指標\n",
    "                precision, recall, mrr, ndcg = self.calculate_metrics(selected, rel)\n",
    "                metrics_list.append((precision, recall, mrr, ndcg))\n",
    "            \n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            # 計算平均指標\n",
    "            avg_metrics = np.mean(metrics_list, axis=0)\n",
    "            diversity = self.calculate_diversity(selected, doc_embeddings)\n",
    "            \n",
    "            return SearchMetrics(\n",
    "                name=\"MMR\",\n",
    "                search_time=search_time,\n",
    "                precision_at_k=avg_metrics[0],\n",
    "                recall_at_k=avg_metrics[1],\n",
    "                mrr=avg_metrics[2],\n",
    "                ndcg=avg_metrics[3],\n",
    "                diversity=diversity,\n",
    "                explanation=\"平衡相關性與多樣性的檢索方法\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"MMR 評估失敗: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def evaluate_bm25(\n",
    "        self,\n",
    "        documents: List[str],\n",
    "        queries: List[str],\n",
    "        relevance: List[List[int]]\n",
    "    ) -> SearchMetrics:\n",
    "        \"\"\"評估 BM25 搜尋\"\"\"\n",
    "        try:\n",
    "            # 初始化 BM25\n",
    "            tokenized_docs = [doc.lower().split() for doc in documents]\n",
    "            bm25 = BM25Okapi(tokenized_docs)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            metrics_list = []\n",
    "            \n",
    "            for query, rel in zip(queries, relevance):\n",
    "                # 進行搜尋\n",
    "                tokenized_query = query.lower().split()\n",
    "                scores = bm25.get_scores(tokenized_query)\n",
    "                results = np.argsort(-scores)[:5].tolist()\n",
    "                \n",
    "                # 計算評估指標\n",
    "                precision, recall, mrr, ndcg = self.calculate_metrics(results, rel)\n",
    "                metrics_list.append((precision, recall, mrr, ndcg))\n",
    "            \n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            # 計算平均指標\n",
    "            avg_metrics = np.mean(metrics_list, axis=0)\n",
    "            \n",
    "            # 為了計算多樣性，需要獲取文檔的嵌入向量\n",
    "            doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "            diversity = self.calculate_diversity(results, doc_embeddings)\n",
    "            \n",
    "            return SearchMetrics(\n",
    "                name=\"BM25\",\n",
    "                search_time=search_time,\n",
    "                precision_at_k=avg_metrics[0],\n",
    "                recall_at_k=avg_metrics[1],\n",
    "                mrr=avg_metrics[2],\n",
    "                ndcg=avg_metrics[3],\n",
    "                diversity=diversity,\n",
    "                explanation=\"基於詞頻與文檔長度的概率檢索模型\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"BM25 評估失敗: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def run_evaluation(self):\n",
    "        \"\"\"執行評估\"\"\"\n",
    "        documents, queries, relevance = self.prepare_test_data()\n",
    "        \n",
    "        # 評估各個搜尋方法\n",
    "        evaluations = [\n",
    "            self.evaluate_cosine(documents, queries, relevance),\n",
    "            self.evaluate_mmr(documents, queries, relevance),\n",
    "            self.evaluate_bm25(documents, queries, relevance)\n",
    "        ]\n",
    "        \n",
    "        # 轉換為 DataFrame\n",
    "        df = pd.DataFrame([\n",
    "            {\n",
    "                \"搜尋方法\": e.name,\n",
    "                \"搜尋時間 (秒)\": round(e.search_time, 3),\n",
    "                \"Precision@5\": round(e.precision_at_k, 3),\n",
    "                \"Recall@5\": round(e.recall_at_k, 3),\n",
    "                \"MRR\": round(e.mrr, 3),\n",
    "                \"NDCG@5\": round(e.ndcg, 3),\n",
    "                \"多樣性\": round(e.diversity, 3),\n",
    "                \"說明\": e.explanation\n",
    "            }\n",
    "            for e in evaluations\n",
    "        ])\n",
    "        \n",
    "        # 設定顯示格式\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        \n",
    "        print(\"\\n=== 相似度搜尋方法比較結果 ===\")\n",
    "        print(f\"測試時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"測試文檔數: {len(documents)}\")\n",
    "        print(f\"測試查詢數: {len(queries)}\")\n",
    "        print(\"\\n\" + str(df))\n",
    "        \n",
    "        # 輸出建議\n",
    "        print(\"\\n=== 使用建議 ===\")\n",
    "        print(\"1. 一般場景建議使用餘弦相似度：簡單有效，實現容易\")\n",
    "        print(\"2. 需要結果多樣性時建議使用 MMR：可以避免結果過於相似\")\n",
    "        print(\"3. 文本搜尋場景建議使用 BM25：特別適合關鍵詞匹配\")\n",
    "        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LangChain 0.3+ 相似度搜尋方法比較 ===\n",
      "\n",
      "\n",
      "=== 相似度搜尋方法比較結果 ===\n",
      "測試時間: 2025-02-15 18:25:58\n",
      "測試文檔數: 10\n",
      "測試查詢數: 5\n",
      "\n",
      "                搜尋方法  搜尋時間 (秒)  Precision@5  Recall@5  MRR  NDCG@5    多樣性  \\\n",
      "0  Cosine Similarity     3.129         0.48     0.933  1.0   0.920  0.164   \n",
      "1                MMR     1.914         0.32     0.650  1.0   0.705  0.194   \n",
      "2               BM25     0.001         0.32     0.633  1.0   0.710  0.180   \n",
      "\n",
      "                 說明  \n",
      "0   基於向量空間中的夾角計算相似度  \n",
      "1    平衡相關性與多樣性的檢索方法  \n",
      "2  基於詞頻與文檔長度的概率檢索模型  \n",
      "\n",
      "=== 使用建議 ===\n",
      "1. 一般場景建議使用餘弦相似度：簡單有效，實現容易\n",
      "2. 需要結果多樣性時建議使用 MMR：可以避免結果過於相似\n",
      "3. 文本搜尋場景建議使用 BM25：特別適合關鍵詞匹配\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"主程式\"\"\"\n",
    "    print(\"=== LangChain 0.3+ 相似度搜尋方法比較 ===\\n\")\n",
    "    \n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        logger.error(\"請先設定 OPENAI_API_KEY 環境變數！\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        evaluator = SearchMethodEvaluator()\n",
    "        evaluator.run_evaluation()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"評估過程發生錯誤: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
