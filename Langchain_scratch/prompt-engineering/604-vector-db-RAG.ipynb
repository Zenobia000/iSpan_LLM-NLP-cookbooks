{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve arguments generated from scratch (vector database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "## 設定 OpenAI API Key 變數\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai api GPT LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=1000):\n",
    "  payload = { \"model\": model, \"temperature\": temperature, \"messages\": messages, \"max_tokens\": max_tokens }\n",
    "  headers = { \"Authorization\": f'Bearer {openai_api_key}', \"Content-Type\": \"application/json\" }\n",
    "  response = requests.post('https://api.openai.com/v1/chat/completions', headers = headers, data = json.dumps(payload) )\n",
    "  obj = json.loads(response.text)\n",
    "  if response.status_code == 200 :\n",
    "    return obj[\"choices\"][0][\"message\"][\"content\"]\n",
    "  else :\n",
    "    return obj[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai api GPT embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(input, dimensions = 1536, model=\"text-embedding-3-small\"):\n",
    "  payload = { \"input\": input, \"model\": model, \"dimensions\": dimensions }\n",
    "  headers = { \"Authorization\": f'Bearer {openai_api_key}', \"Content-Type\": \"application/json\" }\n",
    "  response = requests.post('https://api.openai.com/v1/embeddings', headers = headers, data = json.dumps(payload) )\n",
    "  obj = json.loads(response.text)\n",
    "  if response.status_code == 200 :\n",
    "    return obj[\"data\"][0][\"embedding\"]\n",
    "  else :\n",
    "    return obj[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Document Loader from langchain\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf\n",
    "\n",
    "Load PDF using pypdf into array of documents, where each document contains the page content and metadata with page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試資料\n",
    "\n",
    "2023台灣產業AI化大調查完整報告.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./2023台灣產業AI化大調查完整報告.pdf\")\n",
    "text_docs = loader.load()\n",
    "\n",
    "# 抓取網站資料\n",
    "#from langchain.document_loaders import WebBaseLoader\n",
    "#loader = WebBaseLoader(\"https://eugeneyan.com/writing/llm-patterns/\")\n",
    "#text_docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='', metadata={'source': './2023台灣產業AI化大調查完整報告.pdf', 'page': 0})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install Chroma vector database\n",
    "\n",
    "https://www.trychroma.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection collections already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# In-memory chroma\u001b[39;00m\n\u001b[0;32m      3\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m----> 5\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollections\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\api\\client.py:198\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[1;34m(self, name, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\api\\segment.py:167\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[1;34m(self, name, metadata, embedding_function, data_loader, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    163\u001b[0m check_index_name(name)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m uuid4()\n\u001b[1;32m--> 167\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n\u001b[0;32m    178\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mcreate_segments(coll)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\chromadb\\db\\mixins\\sysdb.py:225\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[1;34m(self, id, name, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[0;32m    220\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[0;32m    221\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    223\u001b[0m         )\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assignment_policy\u001b[38;5;241m.\u001b[39massign_collection(\u001b[38;5;28mid\u001b[39m)\n\u001b[0;32m    228\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    230\u001b[0m     topic\u001b[38;5;241m=\u001b[39mtopic,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[0;32m    236\u001b[0m )\n",
      "\u001b[1;31mUniqueConstraintError\u001b[0m: Collection collections already exists"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "# In-memory chroma\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection = chroma_client.create_collection(name=\"collections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete a collection if you want\n",
    "# chroma_client.delete_collection(\"collections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用 langchain 來對提取出來的 PDF 文本進行 chunks 分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將切割好的 chunk 加入到 chroma collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './2023台灣產業AI化大調查完整報告.pdf', 'page': 0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in text_docs:\n",
    "    chunks = text_splitter.split_text(page.page_content)\n",
    "\n",
    "    if chunks == []:\n",
    "        continue\n",
    "\n",
    "    collection.add(\n",
    "        documents = chunks,\n",
    "        embeddings = [ get_embeddings(chunk) for chunk in chunks ] , # chroma 有內建的 embedding 功能，可以直接使用，但也可以指定自己的 embedding\n",
    "        metadatas = [ { \"page\": page.metadata['page'], \"date\": \"2024-03-31\" } for x in range( len(chunks) ) ], # 可以加入 metadata 作為之後檢索過濾條件\n",
    "        ids=[f\"doc-1-page-{page.metadata['page']}-chunk-{x}\" for x in range( len(chunks) ) ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"哪一個產業對於AI的落地發展較全面?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 透過 chroma 提供的 API 匹配最相似的 chunks\n",
    "\n",
    "Chroma API 文件: https://docs.trychroma.com/usage-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings = get_embeddings(question),\n",
    "    # 可有 where 參數可針對上述的 metadatas 做過濾，例如日期、頁數等\n",
    "    n_results=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc-1-page-24-chunk-0',\n",
       "   'doc-1-page-6-chunk-0',\n",
       "   'doc-1-page-6-chunk-1']],\n",
       " 'distances': [[0.6292528510093689, 0.7028548717498779, 0.7053892612457275]],\n",
       " 'metadatas': [[{'date': '2024-03-31', 'page': 24},\n",
       "   {'date': '2024-03-31', 'page': 6},\n",
       "   {'date': '2024-03-31', 'page': 6}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['25\\n2023 �� AI化大調查趨勢與管理 策略與分析Total 資通訊科技業 (ICT) 專業服務業 零售貿易服務業 製造業 / 政府機關 / 其他\\n17.8  \\n平均分數 (0-100  分) 25.5 14.3 14.1 10.4\\n目前仍在規劃中 / 沒有應用過任何 AI技術 37.2% 22.3% 35.1% 43.2% 60.5%\\n生成式 AI( 不包含使用現成服務，如 ChatGPT 、Copilot ) 28.6% 37.7% 26.0% 35.1% 13.6%\\nMachine Learning(ML) 25.8% 37.7% 16.9% 21.6% 17.3%\\n電腦視覺 22.5% 34.6% 14.3% 13.5% 14.8%\\n自然語言處理 20.0% 26.9% 20.8% 18.9% 8.6%\\n語音與音訊處理 18.8% 23.8% 26.0% 10.8% 7.4%\\nDeep Learning(DL) 16.9% 28.5% 11.7% 2.7% 9.9%\\n推薦系統 12.9% 11.5% 11.7% 18.9% 13.6%\\nAutoML / Low Code AI / No Code AI 9.8% 13.8% 6.5% 10.8% 6.2%\\nEdge AI 9.5% 18.5% 5.2% .0% 3.7%\\nMLOps 8.0% 14.6% 3.9% 2.7% 3.7%\\nReinforcement Learning(RL) 5.5% 9.2% .0% 5.4% 4.9%\\nBase:N=325 130 77 37 81Q. 貴公司曾應用以上數據在哪些 AI 技術領域？ (複 選) Technical 1企業曾應用的 AI技術項目\\n整體產業有近四成仍在規劃或沒有應用任何 AI 技術項目。而生成式 AI 的出現，\\n提供了企業新的技術選擇，相較於去年使用的技術以機器學習 (含深度學習 ) 技術為主， 並多使用在電腦視覺相關的應用場景， 如辨識、 偵測、 追蹤與分割等功能上。\\n2023 年的前三大應用 AI 的技術領域為生成式 AI、Machine Learning (ML)、電腦\\n視覺。2023 整體產業 AI 化表現',\n",
       "   '7\\n2023 �� AI化大調查趨勢與管理 策略與分析模型） +Automation（自動化流程），三者缺一不可。簡單來說，企業思考 AI應\\n用及導入，是要通過定義自身在這三件事上的狀態。 \\nData：自己掌握的數據或是外部數據，是否乾淨或需要清洗？怎麼\\n存儲如何調用，是否需要建立數據中台？資安問題及法規限制，是\\n否有制度能管理？數據的持續有效性、未來性，及數據可推導出的\\n價值。\\nModel：模型歸屬、費用、調用方式、是否真的可滿足需求及可持\\n續性，配合模型的雲端及地端架構、是否有對企業商業知識充足的\\n技術人員可以做出技術選情的建議？模型及架構的運營及永續性、\\n資安及可信賴度？\\nAutomation ：是人工智慧或是工人智慧？自動化的結果不是情感性\\n的變得更科技了。而是有可量化的指標，能看出實際提升的產出。\\n若部分自動化，但仍然造成後續問題，那又何苦呢？\\n當然，企業不一定需要「人工智慧」來解決自己的問題，光是能清楚梳理問題，\\n可能就能透過軟體服務或是工作流調整、管理制度等不同的方式去改善或解決問\\n題。是不是「數位轉型」或是「AI 應用」，其實本質上不重要，真正重要的是懂\\n得科學的分析需求及創造新的工作模式，以應對持續變動的未來。具備以上三個面向的整合，也是在擁有充足的數據作為基礎，建立合理的模型來分析和預測或產\\n出，並將這些模型應用於自動化流程中，才能真正實現 AI的應用價值。\\n所以，下一步？\\n本次大調查最重要也期待達成的目標， 是建立企業面對當前 AI浪潮的思考角度。\\n理解導入 AI並不是找到最完美的解決方案，然後花錢就能解決的問題。付費購買\\n最先進、最強大的軟體也不見得能解決企業所面臨的問題。企業有興趣導入 AI，\\n應該首先思考的是「可用性」及「永續性」。商業模式的可用性來自於對問題的清\\n晰理解，及對現況的清楚掌握；數位環境與人才的永續性來自如何引入或培養會使\\n用AI的人才，然後給予資源支援，調整組織結構，協助人才內部將 AI生根落地。\\n從培訓員工使用 AI工具到重塑組織文化，都是企業開始 AI導入之旅的重要步驟。\\n市場上嘈雜的風聲和絢爛的花火很快就會消散， 而真正掌握 AI應用能力的企業，\\n才是能持續成長且穩健經營的。透過對 AI與企業的關係、AI 應用的核心要素和導\\n入AI的起步點的深入分析， 我們可以更好地理解和應對 AI時代帶來的挑戰與機遇。',\n",
       "   '入AI的起步點的深入分析， 我們可以更好地理解和應對 AI時代帶來的挑戰與機遇。\\n因此，企業應該從現在開始，探索並實現 AI的應用價值，並不斷調整和優化策略，\\n以確保持續的競爭優勢和企業成長。']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將 retrieve 的結果整理成一個完整的 context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 25\n",
      "2023 �� AI化大調查趨勢與管理 策略與分析Total 資通訊科技業 (ICT) 專業服務業 零售貿易服務業 製造業 / 政府機關 / 其他\n",
      "17.8  \n",
      "平均分數 (0-100  分) 25.5 14.3 14.1 10.4\n",
      "目前仍在規劃中 / 沒有應用過任何 AI技術 37.2% 22.3% 35.1% 43.2% 60.5%\n",
      "生成式 AI( 不包含使用現成服務，如 ChatGPT 、Copilot ) 28.6% 37.7% 26.0% 35.1% 13.6%\n",
      "Machine Learning(ML) 25.8% 37.7% 16.9% 21.6% 17.3%\n",
      "電腦視覺 22.5% 34.6% 14.3% 13.5% 14.8%\n",
      "自然語言處理 20.0% 26.9% 20.8% 18.9% 8.6%\n",
      "語音與音訊處理 18.8% 23.8% 26.0% 10.8% 7.4%\n",
      "Deep Learning(DL) 16.9% 28.5% 11.7% 2.7% 9.9%\n",
      "推薦系統 12.9% 11.5% 11.7% 18.9% 13.6%\n",
      "AutoML / Low Code AI / No Code AI 9.8% 13.8% 6.5% 10.8% 6.2%\n",
      "Edge AI 9.5% 18.5% 5.2% .0% 3.7%\n",
      "MLOps 8.0% 14.6% 3.9% 2.7% 3.7%\n",
      "Reinforcement Learning(RL) 5.5% 9.2% .0% 5.4% 4.9%\n",
      "Base:N=325 130 77 37 81Q. 貴公司曾應用以上數據在哪些 AI 技術領域？ (複 選) Technical 1企業曾應用的 AI技術項目\n",
      "整體產業有近四成仍在規劃或沒有應用任何 AI 技術項目。而生成式 AI 的出現，\n",
      "提供了企業新的技術選擇，相較於去年使用的技術以機器學習 (含深度學習 ) 技術為主， 並多使用在電腦視覺相關的應用場景， 如辨識、 偵測、 追蹤與分割等功能上。\n",
      "2023 年的前三大應用 AI 的技術領域為生成式 AI、Machine Learning (ML)、電腦\n",
      "視覺。2023 整體產業 AI 化表現\n",
      "* 7\n",
      "2023 �� AI化大調查趨勢與管理 策略與分析模型） +Automation（自動化流程），三者缺一不可。簡單來說，企業思考 AI應\n",
      "用及導入，是要通過定義自身在這三件事上的狀態。 \n",
      "Data：自己掌握的數據或是外部數據，是否乾淨或需要清洗？怎麼\n",
      "存儲如何調用，是否需要建立數據中台？資安問題及法規限制，是\n",
      "否有制度能管理？數據的持續有效性、未來性，及數據可推導出的\n",
      "價值。\n",
      "Model：模型歸屬、費用、調用方式、是否真的可滿足需求及可持\n",
      "續性，配合模型的雲端及地端架構、是否有對企業商業知識充足的\n",
      "技術人員可以做出技術選情的建議？模型及架構的運營及永續性、\n",
      "資安及可信賴度？\n",
      "Automation ：是人工智慧或是工人智慧？自動化的結果不是情感性\n",
      "的變得更科技了。而是有可量化的指標，能看出實際提升的產出。\n",
      "若部分自動化，但仍然造成後續問題，那又何苦呢？\n",
      "當然，企業不一定需要「人工智慧」來解決自己的問題，光是能清楚梳理問題，\n",
      "可能就能透過軟體服務或是工作流調整、管理制度等不同的方式去改善或解決問\n",
      "題。是不是「數位轉型」或是「AI 應用」，其實本質上不重要，真正重要的是懂\n",
      "得科學的分析需求及創造新的工作模式，以應對持續變動的未來。具備以上三個面向的整合，也是在擁有充足的數據作為基礎，建立合理的模型來分析和預測或產\n",
      "出，並將這些模型應用於自動化流程中，才能真正實現 AI的應用價值。\n",
      "所以，下一步？\n",
      "本次大調查最重要也期待達成的目標， 是建立企業面對當前 AI浪潮的思考角度。\n",
      "理解導入 AI並不是找到最完美的解決方案，然後花錢就能解決的問題。付費購買\n",
      "最先進、最強大的軟體也不見得能解決企業所面臨的問題。企業有興趣導入 AI，\n",
      "應該首先思考的是「可用性」及「永續性」。商業模式的可用性來自於對問題的清\n",
      "晰理解，及對現況的清楚掌握；數位環境與人才的永續性來自如何引入或培養會使\n",
      "用AI的人才，然後給予資源支援，調整組織結構，協助人才內部將 AI生根落地。\n",
      "從培訓員工使用 AI工具到重塑組織文化，都是企業開始 AI導入之旅的重要步驟。\n",
      "市場上嘈雜的風聲和絢爛的花火很快就會消散， 而真正掌握 AI應用能力的企業，\n",
      "才是能持續成長且穩健經營的。透過對 AI與企業的關係、AI 應用的核心要素和導\n",
      "入AI的起步點的深入分析， 我們可以更好地理解和應對 AI時代帶來的挑戰與機遇。\n",
      "* 入AI的起步點的深入分析， 我們可以更好地理解和應對 AI時代帶來的挑戰與機遇。\n",
      "因此，企業應該從現在開始，探索並實現 AI的應用價值，並不斷調整和優化策略，\n",
      "以確保持續的競爭優勢和企業成長。\n"
     ]
    }
   ],
   "source": [
    "documents = results['documents'][0]\n",
    "context = '\\n'.join('* ' + doc for doc in documents)\n",
    "\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將整理出來的 context 結合設計好的 prompt 送入 LLM 進行問答\n",
    "\n",
    "prompt template 參考自 https://docs.anthropic.com/claude/docs/advanced-text-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "I'm going to give you a document. Then I'm going to ask you a question about it. I'd like you to first write down exact quotes of parts of the document that would help answer the question, and then I'd like you to answer the question using facts from the quoted content. Here is the document:\n",
    "\n",
    "<document>\n",
    "{context}\n",
    "</document>\n",
    "\n",
    "Here is the first question:  {question}\n",
    "\n",
    "First, find the quotes from the document that are most relevant to answering the question, and then print them in numbered order. Quotes should be relatively short.\n",
    "\n",
    "If there are no relevant quotes, write \"No relevant quotes\" instead.\n",
    "\n",
    "Then, answer the question, starting with \"Answer:\".  Do not include or reference quoted content verbatim in the answer. Don't say \"According to Quote [1]\" when answering. Instead make references to quotes relevant to each section of the answer solely by adding their bracketed numbers at the end of relevant sentences.\n",
    "\n",
    "Thus, the format of your overall response should look like what's shown between the <example></example> tags.  Make sure to follow the formatting and spacing exactly.\n",
    "\n",
    "<example>\n",
    "\n",
    "Relevant quotes:\n",
    "[1] \"Company X reported revenue of $12 million in 2021.\"\n",
    "[2] \"Almost 90% of revenue came from widget sales, with gadget sales making up the remaining 10%.\"\n",
    "\n",
    "Answer:\n",
    "Company X earned $12 million. [1]  Almost 90% of it was from widget sales. [2]\n",
    "\n",
    "</example>\n",
    "\n",
    "If the question cannot be answered by the document, say so.\n",
    "\n",
    "Answer the question immediately without preamble.\n",
    "請用台灣繁體中文回答.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant quotes:\n",
      "[1] \"生成式 AI( 不包含使用現成服務，如 ChatGPT 、Copilot ) 28.6% 37.7% 26.0% 35.1% 13.6%\"\n",
      "[2] \"Machine Learning(ML) 25.8% 37.7% 16.9% 21.6% 17.3%\"\n",
      "[3] \"電腦視覺 22.5% 34.6% 14.3% 13.5% 14.8%\"\n",
      "[4] \"2023 年的前三大應用 AI 的技術領域為生成式 AI、Machine Learning (ML)、電腦視覺。\"\n",
      "\n",
      "Answer:\n",
      "專業服務業對於AI的落地發展較全面。[1][2][3][4]\n"
     ]
    }
   ],
   "source": [
    "result = get_completion([ {\"role\": \"user\", \"content\": prompt }], model=\"gpt-4-turbo-preview\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo UI 介面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "gr.close_all()\n",
    "\n",
    "def handle_input(query):\n",
    "  results = collection.query(\n",
    "    query_embeddings = get_embeddings(query),\n",
    "    n_results=3\n",
    "  )\n",
    "\n",
    "  documents = results['documents'][0]\n",
    "  context = '\\n'.join('* ' + doc for doc in documents)\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "I'm going to give you a document. Then I'm going to ask you a question about it. I'd like you to first write down exact quotes of parts of the document that would help answer the question, and then I'd like you to answer the question using facts from the quoted content. Here is the document:\n",
    "\n",
    "<document>\n",
    "{context}\n",
    "</document>\n",
    "\n",
    "Here is the first question:  {query}\n",
    "\n",
    "First, find the quotes from the document that are most relevant to answering the question, and then print them in numbered order. Quotes should be relatively short.\n",
    "\n",
    "If there are no relevant quotes, write \"No relevant quotes\" instead.\n",
    "\n",
    "Then, answer the question, starting with \"Answer:\".  Do not include or reference quoted content verbatim in the answer. Don't say \"According to Quote [1]\" when answering. Instead make references to quotes relevant to each section of the answer solely by adding their bracketed numbers at the end of relevant sentences.\n",
    "\n",
    "Thus, the format of your overall response should look like what's shown between the <example></example> tags.  Make sure to follow the formatting and spacing exactly.\n",
    "\n",
    "<example>\n",
    "\n",
    "Relevant quotes:\n",
    "[1] \"Company X reported revenue of $12 million in 2021.\"\n",
    "[2] \"Almost 90% of revenue came from widget sales, with gadget sales making up the remaining 10%.\"\n",
    "\n",
    "Answer:\n",
    "Company X earned $12 million. [1]  Almost 90% of it was from widget sales. [2]\n",
    "\n",
    "</example>\n",
    "\n",
    "If the question cannot be answered by the document, say so.\n",
    "\n",
    "Answer the question immediately without preamble.\n",
    "請用台灣繁體中文回答.\n",
    "\"\"\"\n",
    "\n",
    "  result = get_completion([ {\"role\": \"user\", \"content\": prompt }], model=\"gpt-4-turbo-preview\")\n",
    "  return result\n",
    "\n",
    "demo = gr.Interface(fn=handle_input,\n",
    "                    inputs=[gr.Textbox(label=\"您的問題\", lines=1)],\n",
    "                    outputs=[gr.Textbox(label=\"回答\", lines=10)],\n",
    "                    allow_flagging=\"never\",\n",
    "                    title=\"與財經報告 PDF 聊天\",\n",
    "                    examples=[ [\"AI產業趨勢如何?\"], [\"美國經濟如何?\"], [\"中國經濟如何?\"], [\"台灣經濟如何?\"]]\n",
    "                   )\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
