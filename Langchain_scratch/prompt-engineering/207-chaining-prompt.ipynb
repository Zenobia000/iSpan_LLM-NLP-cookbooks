{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鏈式 prompt, chaining prompts 基本式\n",
    "\n",
    "### case: 翻譯寫作\n",
    "\n",
    "翻譯參考自: https://twitter.com/dotey/status/1710106195640398056\n",
    "\n",
    "類似的改寫思路:\n",
    "\n",
    "* 作文反思改寫 https://twitter.com/mattshumer_/status/1700169043406123294\n",
    "* Chain of Density 摘要法 https://twitter.com/vimota/status/1702503466994982914 和 https://www.facebook.com/minshiTsai/posts/7568225296537280 (中文說明)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "## 設定 OpenAI API Key 變數\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "# openai_api_key = userdata.get('openai_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=1000, format_type=None):\n",
    "  payload = { \"model\": model, \"temperature\": temperature, \"messages\": messages, \"max_tokens\": max_tokens }\n",
    "  if format_type:\n",
    "    payload[\"response_format\"] =  { \"type\": format_type }\n",
    "\n",
    "  headers = { \"Authorization\": f'Bearer {openai_api_key}', \"Content-Type\": \"application/json\" }\n",
    "  response = requests.post('https://api.openai.com/v1/chat/completions', headers = headers, data = json.dumps(payload) )\n",
    "  obj = json.loads(response.text)\n",
    "  if response.status_code == 200 :\n",
    "    return obj[\"choices\"][0][\"message\"][\"content\"]\n",
    "  else :\n",
    "    return obj[\"error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一輪: 整體粗翻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我們很高興地宣布，Google DeepMind的CEO Demis Hassabis代表Gemini團隊介紹了Gemini 1.5。\n",
      "\n",
      "這對於人工智慧來說是令人興奮的時刻。該領域的新進展有潛力在未來幾年使人工智慧對數十億人更有幫助。自Gemini 1.0推出以來，我們一直在測試、改進和增強其功能。\n",
      "\n",
      "今天，我們宣布推出我們的下一代模型：Gemini 1.5。\n",
      "\n",
      "Gemini 1.5大幅提升了性能。它代表了我們方法的一個重大變革，建立在幾乎我們基礎模型開發和基礎設施的每個部分的研究和工程創新之上。這包括使Gemini 1.5更有效地進行訓練和服務，並採用了新的專家混合（MoE）架構。\n",
      "\n",
      "我們首次推出的Gemini 1.5模型是Gemini 1.5 Pro，用於早期測試。這是一個中等大小的多模型模型，經過優化，可擴展到各種任務，並且在性能上與迄今為止我們最大的模型1.0 Ultra相當。它還引入了一個突破性的長篇理解實驗功能。\n",
      "\n",
      "Gemini 1.5 Pro配備標準的128,000令牌上下文窗口。但從今天開始，一小部分開發人員和企業客戶可以通過AI Studio和Vertex AI進行私人預覽，嘗試使用高達100萬令牌的上下文窗口。\n",
      "\n",
      "隨著我們推出完整的100萬令牌上下文窗口，我們正在積極努力進行優化，以改善延遲、減少計算要求並增強用戶體驗。我們很興奮讓人們嘗試這一突破性功能，並在下面分享更多未來可用性的細節。\n",
      "\n",
      "我們下一代模型的持續進步將為人們、開發人員和企業創造、發現和構建使用人工智慧開啟新的可能性。\n"
     ]
    }
   ],
   "source": [
    "# https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note\n",
    "text = \"\"\" Introducing Gemini 1.5\n",
    "By Demis Hassabis, CEO of Google DeepMind, on behalf of the Gemini team\n",
    "\n",
    "This is an exciting time for AI. New advances in the field have the potential to make AI more helpful for billions of people over the coming years. Since introducing Gemini 1.0, we’ve been testing, refining and enhancing its capabilities.\n",
    "\n",
    "Today, we’re announcing our next-generation model: Gemini 1.5.\n",
    "\n",
    "Gemini 1.5 delivers dramatically enhanced performance. It represents a step change in our approach, building upon research and engineering innovations across nearly every part of our foundation model development and infrastructure. This includes making Gemini 1.5 more efficient to train and serve, with a new Mixture-of-Experts (MoE) architecture.\n",
    "\n",
    "The first Gemini 1.5 model we’re releasing for early testing is Gemini 1.5 Pro. It’s a mid-size multimodal model, optimized for scaling across a wide-range of tasks, and performs at a similar level to 1.0 Ultra, our largest model to date. It also introduces a breakthrough experimental feature in long-context understanding.\n",
    "\n",
    "Gemini 1.5 Pro comes with a standard 128,000 token context window. But starting today, a limited group of developers and enterprise customers can try it with a context window of up to 1 million tokens via AI Studio and Vertex AI in private preview.\n",
    "\n",
    "As we roll out the full 1 million token context window, we’re actively working on optimizations to improve latency, reduce computational requirements and enhance the user experience. We’re excited for people to try this breakthrough capability, and we share more details on future availability below.\n",
    "\n",
    "These continued advances in our next-generation models will open up new possibilities for people, developers and enterprises to create, discover and build using AI.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "messages1 = [\n",
    "    {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "            You are Translator, an AI who is skilled in translating English to Chinese Mandarin Taiwanese fluently.\n",
    "            Your task is to translate an article or part of the full article which will be provided to you after you acknowledge\n",
    "            this message and say you’re ready.\n",
    "            Constraints:\n",
    "            * Do not change any of the wording in the text in such a way that the original meaning is changed unless you are fixing typos or correcting the article.\n",
    "            * Do not chat or ask.\n",
    "            * Do not explain any sentences, just translate or leave them as they are.\n",
    "            * When you translate a quote from somebody, please use 「」『』 instead of \"\"\n",
    "\n",
    "            Pleases always respond in Chinese Mandarin Taiwanese and Taiwan terms.\n",
    "            When mixing Chinese and English, add a whitespace between Chinese and English characters.\n",
    "    \"\"\"\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": text}\n",
    "]\n",
    "\n",
    "result1 = get_completion(messages1, model=\"gpt-3.5-turbo-1106\", max_tokens=4096)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二輪: 細部潤飾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google DeepMind 的 CEO Demis Hassabis 代表 Gemini 團隊，興奮地向大家介紹 Gemini 1.5。\n",
      "\n",
      "在人工智慧的領域裡，我們正處於一個充滿激動的時代。近期的突破性進展，預示著在未來幾年內，人工智慧將能為全球數十億人帶來更多幫助。自從我們推出 Gemini 1.0 以來，我們不斷地進行測試、調整和提升，以增強其功能。\n",
      "\n",
      "今日，我們激動地宣布我們的下一代模型：Gemini 1.5。\n",
      "\n",
      "Gemini 1.5 帶來了顯著的性能提升。這代表了我們方法上的一大飛躍，我們在幾乎所有基礎模型開發和基礎設施的部分，都進行了研究和工程創新。這包括讓 Gemini 1.5 在訓練和運行上更加高效，並引入了全新的專家混合（MoE）架構。\n",
      "\n",
      "我們首次推出的用於早期測試的 Gemini 1.5 模型是 Gemini 1.5 Pro。它是一款中型的多模態模型，經過優化，能夠適應廣泛的任務，其性能與我們迄今為止最大的模型 1.0 Ultra 相當。此外，它還帶來了一項在長篇內容理解上的突破性實驗功能。\n",
      "\n",
      "Gemini 1.5 Pro 標配有 128,000 令牌的上下文窗口。但從今天起，少數開發者和企業客戶就能透過 AI Studio 和 Vertex AI 進行私人預覽，體驗高達 100 萬令牌的上下文窗口。\n",
      "\n",
      "隨著我們全面推出 100 萬令牌的上下文窗口，我們正積極優化，以降低延遲、減少計算需求並提升用戶體驗。我們迫不及待想讓大家體驗這一突破性的功能，未來的可用性詳情也將在下方分享。\n",
      "\n",
      "我們下一代模型的持續進步，將為人們、開發者和企業開啟使用人工智慧創造、探索和建構的新可能。\n"
     ]
    }
   ],
   "source": [
    "messages2 = [\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": f\"\"\"\n",
    "            你是一位專業中文翻譯，擅長對翻譯結果進行二次修改和文章潤飾成通俗易懂的中文，我希望你能幫我將以下英文的中文翻譯結果重新意譯和潤色。\n",
    "\n",
    "            * 保留特定的英文術語、數字或名字，並在其前後加上空格，例如：\"生成式 AI 產品\"，\"不超過 10 秒\"。\n",
    "            * 基於直譯結果重新意譯，意譯時務必對照原始英文，不要添加也不要遺漏內容，並以讓翻譯結果通俗易懂，符合中文表達習慣\n",
    "            * 請輸出成台灣使用的繁體中文 zh-tw\n",
    "\n",
    "            英文原文：\n",
    "            {text}\n",
    "\n",
    "            直譯結果：\n",
    "            {result1}\n",
    "\n",
    "            重新潤飾後：\n",
    "            \n",
    "        \"\"\"\n",
    "}\n",
    "]\n",
    "\n",
    "result2 = get_completion(messages2, model=\"gpt-4-turbo-preview\", max_tokens=4096)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人類都不可能一次到位，一次到位的品質可能會比較差，\n",
    "\n",
    "生成式模型本質上就是一個文字接龍，盡可能不要跳躍性思考，而是階段性的思考，讓模型有階段性的思考推理過程，能得到更好的結果。\n",
    "\n",
    "好的品質需要精雕細琢: 費時費力，但是品質會更好\n",
    "(latency 跟 tokens 成本也比較高)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
