{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_ç’°å¢ƒè¨­å®š\n",
    "\n",
    "## ğŸ¯ å­¸ç¿’ç›®æ¨™\n",
    "- å®Œæˆ Python é–‹ç™¼ç’°å¢ƒé…ç½®\n",
    "- å®‰è£å¿…è¦çš„ LangChain å¥—ä»¶\n",
    "- è¨­å®š API é‡‘é‘°ä¸¦æ¸¬è©¦é€£ç·š\n",
    "- é©—è­‰ç’°å¢ƒæ˜¯å¦æ­£å¸¸é‹ä½œ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python ç’°å¢ƒé…ç½®\n",
    "\n",
    "### æª¢æŸ¥ Python ç‰ˆæœ¬\n",
    "å»ºè­°ä½¿ç”¨ Python 3.9 æˆ–ä»¥ä¸Šç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "\n",
    "# æª¢æŸ¥ç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚\n",
    "if sys.version_info >= (3, 9):\n",
    "    print(\"âœ… Python ç‰ˆæœ¬ç¬¦åˆè¦æ±‚\")\n",
    "else:\n",
    "    print(\"âŒ Python ç‰ˆæœ¬éä½ï¼Œå»ºè­°å‡ç´šåˆ° 3.9+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è™›æ“¬ç’°å¢ƒè¨­å®š (é¸æ“‡æ€§)\n",
    "\n",
    "å¦‚æœæ‚¨å¸Œæœ›ä½¿ç”¨è™›æ“¬ç’°å¢ƒï¼Œè«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼š\n",
    "\n",
    "```bash\n",
    "# å»ºç«‹è™›æ“¬ç’°å¢ƒ\n",
    "python -m venv storm_writing_env\n",
    "\n",
    "# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (Windows)\n",
    "storm_writing_env\\Scripts\\activate\n",
    "\n",
    "# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (macOS/Linux)\n",
    "source storm_writing_env/bin/activate\n",
    "\n",
    "# å®‰è£ Jupyter\n",
    "pip install jupyter\n",
    "\n",
    "# å•Ÿå‹• Jupyter Notebook\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. å¥—ä»¶å®‰è£\n",
    "\n",
    "### æ ¸å¿ƒå¥—ä»¶æ¸…å–®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦å¥—ä»¶å®‰è£\n",
    "!pip install langchain langchain-openai langchain-community python-dotenv requests beautifulsoup4 duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é©—è­‰å¥—ä»¶å®‰è£\n",
    "import importlib\n",
    "\n",
    "packages = {\n",
    "    'langchain': 'langchain',\n",
    "    'langchain_openai': 'langchain-openai',\n",
    "    'langchain_community': 'langchain-community',\n",
    "    'dotenv': 'python-dotenv',\n",
    "    'requests': 'requests',\n",
    "    'bs4': 'beautifulsoup4',\n",
    "    'duckduckgo_search': 'duckduckgo-search'\n",
    "}\n",
    "\n",
    "print(\"ğŸ“¦ å¥—ä»¶å®‰è£æª¢æŸ¥:\")\n",
    "for package, install_name in packages.items():\n",
    "    try:\n",
    "        module = importlib.import_module(package)\n",
    "        if hasattr(module, '__version__'):\n",
    "            version = module.__version__\n",
    "        else:\n",
    "            version = \"å·²å®‰è£\"\n",
    "        print(f\"âœ… {install_name}: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {install_name}: æœªå®‰è£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. API é‡‘é‘°è¨­å®š\n",
    "\n",
    "### å»ºç«‹ .env æª”æ¡ˆ\n",
    "åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„å»ºç«‹ `.env` æª”æ¡ˆï¼Œå…§å®¹å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ç¯„ä¾‹ .env æª”æ¡ˆ\n",
    "import os\n",
    "\n",
    "env_content = '''\n",
    "# OpenAI API è¨­å®š\n",
    "OPENAI_API_KEY=your-openai-api-key-here\n",
    "\n",
    "# å¯é¸çš„å…¶ä»– API\n",
    "ANTHROPIC_API_KEY=your-anthropic-api-key-here\n",
    "SERPAPI_API_KEY=your-serpapi-key-here\n",
    "'''\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ .env æª”æ¡ˆ\n",
    "if not os.path.exists('.env'):\n",
    "    with open('.env', 'w', encoding='utf-8') as f:\n",
    "        f.write(env_content)\n",
    "    print(\"âœ… å·²å»ºç«‹ .env ç¯„ä¾‹æª”æ¡ˆ\")\n",
    "    print(\"âš ï¸  è«‹ç·¨è¼¯ .env æª”æ¡ˆï¼Œå¡«å…¥æ‚¨çš„å¯¦éš› API é‡‘é‘°\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  .env æª”æ¡ˆå·²å­˜åœ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼‰å…¥ç’°å¢ƒè®Šæ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv()\n",
    "\n",
    "# æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦å·²è¨­å®š\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_key and openai_key != 'your-openai-api-key-here':\n",
    "    print(\"âœ… OpenAI API é‡‘é‘°å·²è¨­å®š\")\n",
    "    print(f\"é‡‘é‘°å‰ç¶´: {openai_key[:10]}...\")\n",
    "else:\n",
    "    print(\"âŒ è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®šæ‚¨çš„ OpenAI API é‡‘é‘°\")\n",
    "    print(\"ğŸ’¡ ç²å– API é‡‘é‘°: https://platform.openai.com/api-keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. åŸºç¤åŠŸèƒ½æ¸¬è©¦\n",
    "\n",
    "### OpenAI API é€£ç·šæ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.7,\n",
    "        api_key=os.getenv('OPENAI_API_KEY')\n",
    "    )\n",
    "    \n",
    "    # æ¸¬è©¦åŸºæœ¬åŠŸèƒ½\n",
    "    test_message = HumanMessage(content=\"è«‹ç”¨ä¸€å¥è©±èªªæ˜ä»€éº¼æ˜¯äººå·¥æ™ºæ…§\")\n",
    "    response = llm.invoke([test_message])\n",
    "    \n",
    "    print(\"âœ… OpenAI API é€£ç·šæˆåŠŸ\")\n",
    "    print(f\"å›æ‡‰: {response.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ OpenAI API é€£ç·šå¤±æ•—: {str(e)}\")\n",
    "    print(\"ğŸ’¡ è«‹æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦æ­£ç¢ºè¨­å®š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¶²è·¯æœå°‹åŠŸèƒ½æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import requests\n",
    "\n",
    "# æ¸¬è©¦ DuckDuckGo æœå°‹\n",
    "try:\n",
    "    ddgs = DDGS()\n",
    "    results = list(ddgs.text(\"äººå·¥æ™ºæ…§æœ€æ–°ç™¼å±•\", max_results=3))\n",
    "    \n",
    "    print(\"âœ… ç¶²è·¯æœå°‹åŠŸèƒ½æ­£å¸¸\")\n",
    "    print(f\"æœå°‹åˆ° {len(results)} ç­†çµæœ\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. {result['title'][:50]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç¶²è·¯æœå°‹åŠŸèƒ½ç•°å¸¸: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¶²é å…§å®¹æ“·å–æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_url(url, max_length=500):\n",
    "    \"\"\"å¾ç¶²å€æ“·å–æ–‡å­—å…§å®¹\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # ç§»é™¤ script å’Œ style å…ƒç´ \n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        \n",
    "        # æ“·å–æ–‡å­—å…§å®¹\n",
    "        text = soup.get_text()\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "        return text[:max_length] if len(text) > max_length else text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"æ“·å–å¤±æ•—: {str(e)}\"\n",
    "\n",
    "# æ¸¬è©¦ç¶²é å…§å®¹æ“·å–\n",
    "test_url = \"https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD\"\n",
    "content = extract_text_from_url(test_url)\n",
    "\n",
    "if \"æ“·å–å¤±æ•—\" not in content:\n",
    "    print(\"âœ… ç¶²é å…§å®¹æ“·å–åŠŸèƒ½æ­£å¸¸\")\n",
    "    print(f\"æ“·å–å…§å®¹é è¦½: {content[:100]}...\")\n",
    "else:\n",
    "    print(f\"âŒ {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. å·¥å…·å‡½æ•¸æº–å‚™\n",
    "\n",
    "### å»ºç«‹åŸºç¤å·¥å…·é¡åˆ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STORMTools:\n",
    "    \"\"\"STORM ç³»çµ±åŸºç¤å·¥å…·é›†\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key=None):\n",
    "        self.openai_api_key = openai_api_key or os.getenv('OPENAI_API_KEY')\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7,\n",
    "            api_key=self.openai_api_key\n",
    "        )\n",
    "        \n",
    "    def search_web(self, query, max_results=5):\n",
    "        \"\"\"ç¶²è·¯æœå°‹åŠŸèƒ½\"\"\"\n",
    "        try:\n",
    "            ddgs = DDGS()\n",
    "            results = list(ddgs.text(query, max_results=max_results))\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"æœå°‹éŒ¯èª¤: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_content(self, url, max_length=1000):\n",
    "        \"\"\"æ“·å–ç¶²é å…§å®¹\"\"\"\n",
    "        return extract_text_from_url(url, max_length)\n",
    "    \n",
    "    def generate_text(self, prompt):\n",
    "        \"\"\"ä½¿ç”¨ LLM ç”Ÿæˆæ–‡å­—\"\"\"\n",
    "        try:\n",
    "            message = HumanMessage(content=prompt)\n",
    "            response = self.llm.invoke([message])\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"ç”ŸæˆéŒ¯èª¤: {str(e)}\"\n",
    "    \n",
    "    def test_all_functions(self):\n",
    "        \"\"\"æ¸¬è©¦æ‰€æœ‰åŠŸèƒ½\"\"\"\n",
    "        print(\"ğŸ§ª é–‹å§‹åŠŸèƒ½æ¸¬è©¦...\")\n",
    "        \n",
    "        # æ¸¬è©¦æœå°‹\n",
    "        search_results = self.search_web(\"äººå·¥æ™ºæ…§\", 2)\n",
    "        print(f\"âœ… æœå°‹åŠŸèƒ½: æ‰¾åˆ° {len(search_results)} ç­†çµæœ\")\n",
    "        \n",
    "        # æ¸¬è©¦å…§å®¹æ“·å–\n",
    "        if search_results:\n",
    "            content = self.extract_content(search_results[0]['href'])\n",
    "            print(f\"âœ… å…§å®¹æ“·å–: æ“·å–äº† {len(content)} å€‹å­—å…ƒ\")\n",
    "        \n",
    "        # æ¸¬è©¦æ–‡å­—ç”Ÿæˆ\n",
    "        text = self.generate_text(\"è«‹ç°¡è¿°äººå·¥æ™ºæ…§çš„å®šç¾©\")\n",
    "        print(f\"âœ… æ–‡å­—ç”Ÿæˆ: {text[:50]}...\")\n",
    "        \n",
    "        print(\"ğŸ‰ æ‰€æœ‰åŠŸèƒ½æ¸¬è©¦å®Œæˆï¼\")\n",
    "\n",
    "# å»ºç«‹å·¥å…·å¯¦ä¾‹\n",
    "tools = STORMTools()\n",
    "print(\"âœ… STORM å·¥å…·é¡åˆ¥å·²å»ºç«‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®Œæ•´åŠŸèƒ½æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸ·è¡Œå®Œæ•´æ¸¬è©¦\n",
    "tools.test_all_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ç’°å¢ƒæª¢æŸ¥ç¸½çµ\n",
    "\n",
    "### æª¢æŸ¥æ¸…å–®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def environment_check():\n",
    "    \"\"\"å®Œæ•´ç’°å¢ƒæª¢æŸ¥\"\"\"\n",
    "    checks = []\n",
    "    \n",
    "    # Python ç‰ˆæœ¬æª¢æŸ¥\n",
    "    python_ok = sys.version_info >= (3, 9)\n",
    "    checks.append((\"Python 3.9+\", python_ok))\n",
    "    \n",
    "    # å¥—ä»¶æª¢æŸ¥\n",
    "    packages = ['langchain', 'langchain_openai', 'dotenv', 'requests', 'bs4', 'duckduckgo_search']\n",
    "    for package in packages:\n",
    "        try:\n",
    "            importlib.import_module(package)\n",
    "            checks.append((f\"{package} å¥—ä»¶\", True))\n",
    "        except ImportError:\n",
    "            checks.append((f\"{package} å¥—ä»¶\", False))\n",
    "    \n",
    "    # API é‡‘é‘°æª¢æŸ¥\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    api_ok = api_key and api_key != 'your-openai-api-key-here'\n",
    "    checks.append((\"OpenAI API é‡‘é‘°\", api_ok))\n",
    "    \n",
    "    # é¡¯ç¤ºçµæœ\n",
    "    print(\"ğŸ“‹ ç’°å¢ƒæª¢æŸ¥çµæœ:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    all_passed = True\n",
    "    for item, status in checks:\n",
    "        icon = \"âœ…\" if status else \"âŒ\"\n",
    "        print(f\"{icon} {item}\")\n",
    "        if not status:\n",
    "            all_passed = False\n",
    "    \n",
    "    print(\"=\" * 30)\n",
    "    if all_passed:\n",
    "        print(\"ğŸ‰ ç’°å¢ƒè¨­å®šå®Œæˆï¼å¯ä»¥é–‹å§‹ä¸‹ä¸€æ­¥é–‹ç™¼\")\n",
    "    else:\n",
    "        print(\"âš ï¸  è«‹è§£æ±ºä¸Šè¿°å•é¡Œå¾Œå†ç¹¼çºŒ\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "# åŸ·è¡Œæª¢æŸ¥\n",
    "environment_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ æœ¬ç« å°çµ\n",
    "\n",
    "### å®Œæˆé …ç›®\n",
    "- âœ… Python ç’°å¢ƒç¢ºèª\n",
    "- âœ… å¿…è¦å¥—ä»¶å®‰è£\n",
    "- âœ… API é‡‘é‘°è¨­å®š\n",
    "- âœ… åŸºç¤åŠŸèƒ½æ¸¬è©¦\n",
    "- âœ… å·¥å…·é¡åˆ¥å»ºç«‹\n",
    "\n",
    "### ä¸‹ä¸€æ­¥é å‘Š\n",
    "åœ¨ä¸‹ä¸€å€‹ notebookã€Œ02_æ‰‹å‹•ç‰ˆ_ç ”ç©¶æ™ºèƒ½é«”ã€ä¸­ï¼Œæˆ‘å€‘å°‡ï¼š\n",
    "1. å¯¦ä½œ STORM çš„ç¬¬ä¸€å€‹éšæ®µï¼šçŸ¥è­˜æ¢ç´¢\n",
    "2. é–‹ç™¼ç ”ç©¶æ™ºèƒ½é«”çš„æ ¸å¿ƒåŠŸèƒ½\n",
    "3. å¯¦ç¾å¤šè§’åº¦å•é¡Œç”Ÿæˆ\n",
    "4. å»ºç«‹è³‡æ–™æ”¶é›†èˆ‡é©—è­‰æ©Ÿåˆ¶\n",
    "\n",
    "### æ•…éšœæ’é™¤\n",
    "å¦‚æœé‡åˆ°å•é¡Œï¼Œè«‹æª¢æŸ¥ï¼š\n",
    "1. **ç¶²è·¯é€£ç·š**: ç¢ºä¿å¯ä»¥æ­£å¸¸è¨ªå•ç¶²éš›ç¶²è·¯\n",
    "2. **API é…é¡**: ç¢ºèª OpenAI å¸³æˆ¶æœ‰è¶³å¤ çš„ä½¿ç”¨é…é¡\n",
    "3. **é˜²ç«ç‰†è¨­å®š**: æŸäº›ä¼æ¥­ç¶²è·¯å¯èƒ½æœƒé˜»æ“‹ API è«‹æ±‚\n",
    "4. **å¥—ä»¶ç‰ˆæœ¬**: å¦‚æœæœ‰ç›¸å®¹æ€§å•é¡Œï¼Œå¯ä»¥å˜—è©¦æŒ‡å®šç‰¹å®šç‰ˆæœ¬\n",
    "\n",
    "---\n",
    "\n",
    "*ç’°å¢ƒè¨­å®šå®Œæˆï¼ç¾åœ¨æ‚¨å·²ç¶“å…·å‚™é–‹ç™¼ STORM ç³»çµ±æ‰€éœ€çš„æ‰€æœ‰å·¥å…·ã€‚è®“æˆ‘å€‘é–‹å§‹å¯¦éš›çš„æ™ºèƒ½é«”é–‹ç™¼ä¹‹æ—…ï¼*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}