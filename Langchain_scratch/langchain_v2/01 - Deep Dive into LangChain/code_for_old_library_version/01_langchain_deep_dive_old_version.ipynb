{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288ce9a8",
   "metadata": {
    "id": "288ce9a8"
   },
   "source": [
    "# LangChain Basics\n",
    "\n",
    "Last Update: Jan 10, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "002d92f1",
   "metadata": {
    "executionInfo": {
     "elapsed": 6656,
     "status": "ok",
     "timestamp": 1695281250556,
     "user": {
      "displayName": "Andrei Dumitrescu",
      "userId": "04285534149796751164"
     },
     "user_tz": -180
    },
    "id": "002d92f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbd8a7",
   "metadata": {},
   "source": [
    "Download [requirements.txt](\n",
    "https://drive.google.com/file/d/1IeTp3JOjhkHYr21tEEh_7X8ozx39v2xc/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff28727",
   "metadata": {
    "id": "4ff28727"
   },
   "outputs": [],
   "source": [
    "# !pip - installs the packages in the base environment\n",
    "# pip - installs the packages in the virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13460ea3-2a18-4c3d-ab58-efd3f3dff953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf2f431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4913,
     "status": "ok",
     "timestamp": 1695281268475,
     "user": {
      "displayName": "Andrei Dumitrescu",
      "userId": "04285534149796751164"
     },
     "user_tz": -180
    },
    "id": "bdf2f431",
    "outputId": "01809e7f-0539-4eae-b6af-19117ab595eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.354\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/dda/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/env-old/lib/python3.11/site-packages\n",
      "Requires: aiohttp, dataclasses-json, jsonpatch, langchain-community, langchain-core, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b168af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 0.28.1\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: /home/dda/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/env-old/lib/python3.11/site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14256a6",
   "metadata": {
    "id": "d14256a6",
    "outputId": "dd3ada21-4a44-4f41-a463-579295a371b5"
   },
   "outputs": [],
   "source": [
    "# upgrading langchain\n",
    "# pip install langchain --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4407a3a",
   "metadata": {
    "id": "f4407a3a"
   },
   "source": [
    "#### Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9420415",
   "metadata": {
    "id": "d9420415",
    "outputId": "0e64cc2d-6d74-41b7-a8c2-b311e2b72ebc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# loading the API Keys (OpenAI, Pinecone) from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ee709",
   "metadata": {
    "id": "c20ee709"
   },
   "source": [
    "### ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "754cebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054eadaa",
   "metadata": {
    "id": "054eadaa"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9bdecaa",
   "metadata": {
    "id": "f9bdecaa",
    "outputId": "57873169-df9d-492e-9c54-fb9cf2b21008"
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='explain quantum mechanics in one sentence')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "761e06dd",
   "metadata": {
    "id": "761e06dd",
    "outputId": "38f630b1-14d4-4fd5-d39b-70e5f0072d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf subatomarer Ebene und ermöglicht die Berechnung von Wahrscheinlichkeiten für verschiedene physikalische Zustände.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ad29b",
   "metadata": {
    "id": "6d3ad29b"
   },
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a31ca4b",
   "metadata": {
    "id": "3a31ca4b"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "612ed8a8",
   "metadata": {
    "id": "612ed8a8",
    "outputId": "7cf93377-faea-47c8-a86e-d23de5591459"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an experienced virologist.\\nWrite a few sentences about the following virus hiv in german.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following virus {virus} in {language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=template\n",
    ")\n",
    "prompt_template.format(virus='hiv', language='german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b28accc9",
   "metadata": {
    "id": "b28accc9",
    "outputId": "9a33f6f3-5b1c-4688-b5c9-51f1419ce176",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV, das humane Immundefizienz-Virus, ist ein Retrovirus, das das Immunsystem des menschlichen Körpers schwächt. Es wird hauptsächlich durch ungeschützten Geschlechtsverkehr, den Austausch von infizierten Körperflüssigkeiten wie Blut oder Sperma sowie von Mutter auf Kind während der Geburt oder Stillzeit übertragen. HIV führt unbehandelt zur Entwicklung von AIDS, dem Endstadium der Krankheit. Trotz erheblicher Fortschritte in der Behandlung und Prävention bleibt HIV eine ernsthafte globale Gesundheitsbedrohung.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(virus='hiv', language='german')\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d9b84",
   "metadata": {
    "id": "025d9b84"
   },
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd1e5278",
   "metadata": {
    "id": "fd1e5278"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus': 'HSV', 'language': 'french'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be42818a",
   "metadata": {
    "id": "be42818a",
    "outputId": "af68df04-3165-4c7c-ef0e-f6a60d03dd28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'HSV, ou le virus de l'herpès simplex, est un virus courant qui infecte les humains. Il existe deux types d'HSV : le HSV-1, qui provoque principalement des lésions autour de la bouche et le HSV-2, qui est principalement responsable des infections génitales. Ces virus se transmettent par contact direct avec les lésions ou les sécrétions infectées. Bien qu'il n'existe pas de traitement curatif pour l'HSV, des médicaments antiviraux peuvent aider à réduire les symptômes et les récidives. Il est important de se protéger et de pratiquer des rapports sexuels sûrs pour prévenir la transmission de l'HSV.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283cc13",
   "metadata": {
    "id": "f283cc13"
   },
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d68115d",
   "metadata": {
    "id": "9d68115d",
    "outputId": "2aa75fcc-88bb-4972-c9dc-0eec0f0b7d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure! Here's a Python function that implements the concept of softmax:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def softmax(x):\n",
      "    \"\"\"\n",
      "    Compute the softmax of input array x.\n",
      "\n",
      "    Args:\n",
      "        x (numpy array): Input array.\n",
      "\n",
      "    Returns:\n",
      "        numpy array: Softmax of input array.\n",
      "    \"\"\"\n",
      "\n",
      "    # Compute exponentials of input array\n",
      "    exps = np.exp(x)\n",
      "\n",
      "    # Compute softmax probabilities\n",
      "    softmax_probs = exps / np.sum(exps)\n",
      "\n",
      "    return softmax_probs\n",
      "```\n",
      "\n",
      "This function takes in an input array `x` and computes the softmax of that array. It first exponentiates each element of the array, and then divides each exponentiated element by the sum of all exponentiated elements to obtain the softmax probabilities. The function returns the softmax probabilities as a numpy array.\n",
      "\n",
      "You can use this function by calling it and passing your desired input array, like this:\n",
      "\n",
      "```python\n",
      "input_array = np.array([2, 4, 6])\n",
      "\n",
      "softmax_probs = softmax(input_array)\n",
      "\n",
      "print(softmax_probs)\n",
      "```\n",
      "\n",
      "This will output the softmax probabilities for the input array `[2, 4, 6]`.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe provided Python function implements the concept of softmax, which is a mathematical function commonly used in machine learning and statistics to convert a vector of real numbers into a probability distribution. The softmax function takes in an input array (`x`) and computes the softmax of that array.\n",
      "\n",
      "Within the function, the first step is to compute the exponentials of each element in the input array (`x`), which is done using the `np.exp()` function from the NumPy library. This effectively transforms the input array into an array of positive values.\n",
      "\n",
      "Next, the function calculates the sum of all exponentiated elements in the array using the `np.sum()` function. It divides each exponentiated element by this sum to obtain the softmax probabilities.\n",
      "\n",
      "Finally, the function returns the softmax probabilities as a NumPy array.\n",
      "\n",
      "To use this function, you can call it by passing your desired input array. In the example provided, the input array `[2, 4, 6]` is used. After calling the `softmax()` function with this input array, the resulting softmax probabilities are assigned to the variable `softmax_probs`.\n",
      "\n",
      "These probabilities can then be printed using the `print()` function, which outputs \"[0.09003057  0.24472847  0.66524096]\", representing the softmax probabilities for the input array `[2, 4, 6]`. These values indicate the probabilities of each element being selected or chosen based on their relative magnitudes within the input array.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run('softmax')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9c39",
   "metadata": {
    "id": "ed3a9c39"
   },
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f8284aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_experimental -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "631fd9cf",
   "metadata": {
    "id": "631fd9cf"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "115e2fe3",
   "metadata": {
    "id": "115e2fe3",
    "outputId": "e7b894b6-3eee-41b4-faf3-171d2aed2f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate the square root of the factorial of 12, we need to find the factorial of 12 first and then take the square root of the result. We can use the math module in Python to calculate the square root. To display the result with 4 decimal points, we can use the format function or the round function.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have imported the math module, which will allow me to use the square root function.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: math.factorial(12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the factorial of 12, which is 479,001,600.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: math.sqrt(479001600)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the square root of the factorial of 12, which is approximately 21,908.9023.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: round(math.sqrt(479001600), 4)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have rounded the square root of the factorial of 12 to 4 decimal points, which is 21,908.9023.\n",
      "\n",
      "Final Answer: 21,908.9023\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'21,908.9023'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "agent_executor.run('Calculate the square root of the factorial of 12 and display it with 4 decimal points')\n",
    "\n",
    "# agent_executor.run('What is the answer to 5.1 ** 7? \\\n",
    "# Generate the Python code for this and run the code.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0af1eb",
   "metadata": {
    "id": "8f0af1eb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
